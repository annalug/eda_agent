# ğŸ“Š Data Analysis Agent with RAG

An intelligent system for Exploratory Data Analysis (EDA) integrated with Retrieval-Augmented Generation (RAG) for querying technical documents.  
It performs statistical analysis on CSV datasets while enabling semantic search over PDF files using a large language model.

---

## ğŸ—ï¸ Project Structure
```
eda_agent/
â”œâ”€â”€ ğŸ“ data/                 # CSV dataset (creditcard.csv)
â”œâ”€â”€ ğŸ“ rag_files/            # PDF documents used as knowledge base
â”œâ”€â”€ ğŸ“ vectorstore/          # Persisted vector database
â”œâ”€â”€ ğŸ“ venv/                 # Python virtual environment
â”œâ”€â”€ ğŸ”§ agent.py              # Main LangChain agent with tools (EDA + RAG)
â”œâ”€â”€ ğŸ¨ app.py                # Streamlit web interface
â”œâ”€â”€ ğŸ“¥ dataset_download.py   # Automated dataset downloader
â”œâ”€â”€ ğŸ—„ï¸ vectorstore_creator.py # Vectorstore creation from PDFs
â”œâ”€â”€ ğŸ” vectorstore_loader.py  # Vectorstore loader/tester
â”œâ”€â”€ ğŸ”‘ .env                  # Environment variables (GROQ_API_KEY)
â””â”€â”€ ğŸ“– README.md             # Documentation
```


## ğŸ“ Main Files

| File                         | Function                                                                 |
|------------------------------|--------------------------------------------------------------------------|
| **`agent.py`**               | LangChain agent with statistical tools, visualizations, and RAG search   |
| **`app.py`**                 | Streamlit interface with chat, real-time plots, and control panel        |
| **`dataset_download.py`**    | Automatic download of creditcard.csv from Kaggle via KaggleHub           |
| **`vectorstore_creator.py`** | PDF loader, text splitter, embeddings, and ChromaDB vectorstore creation |
| **`vectorstore_loader.py`**  | Safe loader and tester for the persisted vectorstore                     |
| **`.env`**                   | Contains the Groq API key                                                |

## ğŸš€ Features

### ğŸ¤– Intelligent Agent (`agent.py`)
- **Statistical Analysis**: Dataset summary and column-level descriptive statistics  
- **Data Visualization**: Histograms and boxplots generated on demand  
- **RAG System**: Semantic search across technical PDF documents  
- **Specialized Tools**:
  - `search_documents()` â€” semantic PDF retrieval (RAG)
  - `dataset_summary()` â€” dataset shape and name
  - `column_names()` â€” list available dataset columns
  - `column_stats()` â€” statistics for a numeric column
  - `create_histogram()` â€” distribution visualization
  - `create_boxplot()` â€” outlier & quartile inspection

The agent answers general data science concepts directly and only calls tools when necessary.

---

### ğŸ¨ Web Interface (`app.py`)
- **Interactive Chat** with persistent history  
- **Real-Time Visualizations** embedded directly in the chat  
- **Sidebar Control Panel** showing system and dataset status  
- **Responsive Design** for desktop and tablet  
- **State Management** for conversation and session control  

---

### ğŸ“¥ Data Handling (`dataset_download.py`)
- **Automatic Download** of the credit card fraud dataset  
- **Smart Pre-processing** with automatic sampling for large datasets (>10k rows)  
- **Consistent Directory Structure** under `data/`  
- **Integrity Check** to confirm successful download and copy  

---

### ğŸ—„ï¸ RAG System

**Knowledge Base Source**

The RAG system uses content extracted from the book:

**_Probability and Statistics: The Science of Uncertainty_**  
Michael J. Evans and Jeffrey S. Rosenthal  
University of Toronto  

ğŸ“– PDF source:  
https://utstat.utoronto.ca/mikevans/jeffrosenthal/book.pdf  

This material is used for educational and demonstration purposes, allowing the agent to answer theoretical questions about probability, statistics, and data analysis.

---

**`vectorstore_creator.py`**:
- Loads all PDFs from `rag_files/`  
- Splits text into optimized chunks (600 chars, 100 overlap)  
- Generates embeddings with `sentence-transformers/all-MiniLM-L6-v2`  
- Saves a fully persistent ChromaDB vectorstore in `vectorstore/`  

**`vectorstore_loader.py`**:
- Safely loads the vectorstore  
- Performs integrity checks and quick retrieval tests  
- Displays document counts and retrieval quality  

---

## ğŸ› ï¸ Installation & Setup

### Requirements
```bash
pip install streamlit pandas numpy matplotlib langchain groq chromadb sentence-transformers kagglehub python-dotenv

# or
pip install -r requirements.txt
```
Environment Setup

Create your .env file:
```bash
GROQ_API_KEY=your_groq_api_key_here
```
ğŸ¯ Usage Workflow:

1. ğŸ—„ï¸ Prepare the Knowledge Base (RAG)

Add your PDFs to rag_files/ and run:

```
python vectorstore_creator.py
```
2. ğŸ“¥ Download the Example Dataset
```
python dataset_download.py
```
3. ğŸš€ Run the System
```
# Web interface (recommended)
streamlit run app.py

# or via console
python agent.py
```
4. ğŸ’¬ Interact with the Agent

ğŸ“Š Data Analysis Examples:Data Analysis Examples:

    â€œDataset summaryâ€
    
    â€œStatistics for column V1â€
    
    â€œCreate histogram of Amountâ€
    
    â€œWhich columns are available?â€

ğŸ“š Document Retrieval Examples:

    â€œWhat is standard deviation?â€
    
    â€œExplain machine learningâ€
    
    â€œWhat do the documents say about exploratory analysis?â€

ğŸ”§ Technologies Used

    LangChain â€” LLM agents and tooling
    
    Streamlit â€” interactive and responsive UI
    
    Groq API (Llama 3.1 8B Instant) â€” ultra-fast LLM inference
    
    ChromaDB â€” vector database for RAG
    
    HuggingFace â€” Sentence Transformers for embeddings
    
    Pandas / NumPy â€” data processing
    
    Matplotlib â€” visualizations
    
    KaggleHub â€” automated dataset download

âš™ï¸ Technical Configuration

    LLM: llama-3.1-8b-instant (Groq)
    Embeddings: sentence-transformers/all-MiniLM-L6-v2
    Chunk Size: 600 characters
    Chunk Overlap: 100 characters
    Retrieval: Top 3 most relevant documents
    
    Optimizations:
    
    Automatic sampling for large datasets
    
    Conversation buffer with token limits
    
    Robust error handling
    
    Performance configurations to avoid API constraints


